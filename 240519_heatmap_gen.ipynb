{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447c5bf-420b-443f-b771-ab82202d10cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import time\n",
    "import os\n",
    "\n",
    "import tifffile as tif\n",
    "import pandas as pd\n",
    "from PIL import ImageEnhance\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "\n",
    "import patch_gen_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fa76ce-4ce1-4dc4-86e8-188593f88ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6438b-a09b-4819-aa3b-d32ab35f78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../model_name.pth')\n",
    "model = model.to(device)\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45460f4-ac4d-4991-94f4-6d1496c497e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerTestDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, img_path, img_list, transforms = None):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.img_path = img_path\n",
    "        self.img_list = img_list\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "    \n",
    "        filename = self.img_list[index]\n",
    "        image = Image.open(os.path.join(self.img_path, filename))\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, filename\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863c332-683c-4731-ba93-db0336af2c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ab5b18-4110-4179-968d-944bc54ace39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b5983e-7f7b-4256-a2f6-20ddad141d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing part\n",
    "strip_num = 11\n",
    "slide_path = 'H:/WSI from POSTECH/OPM data/colon/cancer/21S-122361A10'\n",
    "slide_test = tif.imread(os.path.join(slide_path, f'{strip_num}.tiff'))\n",
    "img = (slide_test/65535)*255\n",
    "slide = np.asarray(img).astype(np.uint8)\n",
    "#img = Image.fromarray(img)+\n",
    "\n",
    "W, H, C = slide.shape\n",
    "W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037ce05-c0a5-4d0a-a9d5-554a031c93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = f'../test/{strip_num}/'\n",
    "\n",
    "for _,_,files in os.walk(saving_path):\n",
    "    for file in files:\n",
    "        os.remove(os.path.join(saving_path, file))\n",
    "#cord_list = patch_generator_test(xo=0, yo=0, xstep=768, ystep=768, H=H, W=W, patch=1024)\n",
    "#cord_list = patch_gen_test.patch_generator(saving_path, xo=0, yo=0, xstep=384, ystep=384, H=H, W=W, patch_size=512, img=img)\n",
    "#patchlist = pd.DataFrame(cord_list)\n",
    "\n",
    "prob_arr_dim = patch_gen_test.patch_generator(saving_path, xo=0, yo=0, \n",
    "                                              xstep=384, ystep=384, H=H, W=W, patch_size=512, img=slide)\n",
    "prob_arr_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7539c765-514b-4dff-93ba-c625d03735aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_list = []\n",
    "\n",
    "for _, _, files in os.walk(saving_path):\n",
    "    img_list = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351dd450-c7e7-48bc-a5ab-e5b17182688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset2 = CancerTestDataset(saving_path, img_list, get_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e6a27-9351-4477-b761-175ad468211d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset2[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7c2099-24df-4942-969e-a8b53e7c63b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_int = {'BG': 0, 'STR': 1, 'cancer': 2, 'normal': 3}\n",
    "#class_to_int = {'BG': 0, 'LYM': 1, 'STR': 2, 'cancer': 3, 'normal': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97a4bc-f6d5-4c03-a36a-c00fba89f60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction and testing of MODEL\n",
    "\n",
    "def predict_image2(img, model):\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), get_default_device())\n",
    "\n",
    "    pred_sf = model(xb).softmax(dim=1)\n",
    "    probability = format(pred_sf[0][class_to_int['cancer']], '.4f')\n",
    "    #print(pred_sf)\n",
    "    \n",
    "    outputs = model(xb)\n",
    "    pred_values, preds_indx = torch.max(outputs, 1)\n",
    "    #print(probability, preds_indx.item())\n",
    "    #print(pred_values, preds_indx.item(), format(pred_sf[0][preds_indx.item()], '.4f'))\n",
    "\n",
    "    return probability, preds_indx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24a6c1-409c-4904-b3c0-3b51084bdbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9590bd72-4860-4df2-965a-1560a24e5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 ={'x':[], 'y':[], 'idx':[], 'cancer_score':[]}\n",
    "im = np.zeros((W, H))\n",
    "\n",
    "pred_im = np.zeros((512, 512))\n",
    "\n",
    "#prob_arr = np.zeros((prob_arr_dim[0], prob_arr_dim[1]))\n",
    "\n",
    "for i in range(len(test_dataset2)):\n",
    "    image = test_dataset2[i][0]\n",
    "    filename = test_dataset2[i][1]\n",
    "    prediction, pred_indx = predict_image2(image, model)\n",
    "    #print(pred_indx.item())\n",
    "    \n",
    "    #img11 = Image.open(os.path.join(saving_path, img_list[i]))\n",
    "    img11 = Image.open(os.path.join(saving_path, filename))\n",
    "    \n",
    "    #enhancer = ImageEnhance.Color(img11)\n",
    "    #img1 = enhancer.enhance(float(prediction)*4)\n",
    "    \n",
    "    x = int((filename.split('_')[0]).split('x')[1])\n",
    "    y = int((filename.split('_')[1]).split('y')[1])\n",
    "    \n",
    "    #im.paste(img1, (y, x))\n",
    "    \n",
    "    pred2['x'].append(x)\n",
    "    pred2['y'].append(y)\n",
    "    pred2['idx'].append(pred_indx.item())\n",
    "    pred2['cancer_score'].append(prediction)\n",
    "    \n",
    "    prediction = int(float(prediction)*100)\n",
    "    im[x:x+512, y:y+512] = prediction\n",
    "    \n",
    "    '''\n",
    "    #for generating images for the manuscripts\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    ax = plt.subplot(1, 4, 3)\n",
    "    ax.imshow(img11, cmap='gray', alpha=1)\n",
    "    my_cmap = plt.get_cmap('rainbow').copy()\n",
    "    my_cmap.set_under('k', alpha=0)\n",
    "    pred_im[0:512, 0:512] = prediction\n",
    "    print(prediction)\n",
    "    ax.imshow(pred_im,cmap=my_cmap, vmin=20, vmax=100, alpha=0.6, interpolation='bicubic')\n",
    "    fig.savefig(f'{saving_path}{filename}.jpg')\n",
    "    '''\n",
    "    \n",
    "    #prob_arr[y//384][x//384] = prediction\n",
    "    #print([y//384],[x//384])\n",
    "    \n",
    "    #pred2.append(prediction)\n",
    "#im.save(f'{strip_num}_95_74.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dde612-27fe-4ed7-a4e0-db5c7afe3eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr_slide = cv2.cvtColor(slide, cv2.COLOR_BGR2GRAY)\n",
    "#gr_dlide = cv2.resize(gr_slide, (gr_slide.shape[1]//10, gr_slide.shape[0]//10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f92fc-3c4a-41c9-adb3-f44ecaa1a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overlapping images with prediction map\n",
    "import matplotlib\n",
    "\n",
    "fig = plt.figure(figsize=(18,18))\n",
    "#fig2 = plt.figure(figsize=(10,10))\n",
    "#fig = plt.figure()\n",
    "\n",
    "font = {'family' : 'normal',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 10}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "plt.rc('font', size=18)\n",
    "#plt.rc('xtick', labelsize=18)\n",
    "#plt.rc('ytick', labelsize=18)\n",
    "\n",
    "ax2 = plt.subplot(1, 4, 3, aspect='equal')\n",
    "ax2.imshow(np.squeeze(gr_slide), alpha = 1, cmap='gray')\n",
    "\n",
    "#my_cmap = cm.get_cmap(\"gist_rainbow_r\").copy()\n",
    "my_cmap = cm.get_cmap(\"rainbow\").copy()\n",
    "my_cmap.set_under('k', alpha=0)\n",
    "hm = ax2.imshow(im, alpha=0.6, clim=[40,100], cmap=my_cmap, interpolation='gaussian')\n",
    "#fig.colorbar(hm, fraction=0.15)\n",
    "#plt.ylabel('cancer probability in percentage', )\n",
    "fig.savefig(f'{slide_path}/{strip_num}_94_75.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6881381-19c5-4cfe-8d2d-516fd89359d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca0e51-4633-4169-a443-6896ac5b3626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a3bef-6230-4e80-9024-401af7ae6dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
